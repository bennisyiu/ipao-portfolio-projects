{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66770ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyalex\n",
      "  Downloading pyalex-0.18-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: requests in ./myenv/lib/python3.12/site-packages (from pyalex) (2.32.3)\n",
      "Requirement already satisfied: urllib3 in ./myenv/lib/python3.12/site-packages (from pyalex) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests->pyalex) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.12/site-packages (from requests->pyalex) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.12/site-packages (from requests->pyalex) (2025.1.31)\n",
      "Downloading pyalex-0.18-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pyalex\n",
      "Successfully installed pyalex-0.18\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyalex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e272184d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying OpenAlex for 5 DOIs...\n",
      "\n",
      "--- Processing DOI: 10.1177/10963480241229235 ---\n",
      "  Title: Artificial Intelligence in Hospitality and Tourism: Insights From Industry Practices, Research Literature, and Expert Opinions\n",
      "  Journal: N/A (2024)\n",
      "  Authors: Hyunsu Kim, Kevin Kam Fung So, Seunghun Shin, Jing Li\n",
      "  Top Concepts: Hospitality, Tourism, Hospitality industry\n",
      "  Cited By: 30\n",
      "  OpenAlex ID: https://openalex.org/W4391822953\n",
      "\n",
      "--- Processing DOI: 10.1002/adfm.202413884 ---\n",
      "  Title: Hierarchical Engineering on Built‐In Electric Field of Bimetallic Zeolitic Imidazolate Derivatives Towards Amplified Dielectric Loss\n",
      "  Journal: N/A (2024)\n",
      "  Authors: Shijie Zhang, Jiajun Zheng, Di Lan, Zhenguo Gao, Xiaowei Liang, Qingfeng Tian, Zhiwei Zhao, Guanglei Wu\n",
      "  Top Concepts: Materials science, Bimetallic strip, Zeolitic imidazolate framework\n",
      "  Cited By: 26\n",
      "  OpenAlex ID: https://openalex.org/W4403192979\n",
      "\n",
      "--- Processing DOI: 10.1109/TNNLS.2023.3336563 ---\n",
      "  Title: Learning to Aggregate Multi-Scale Context for Instance Segmentation in Remote Sensing Images\n",
      "  Journal: N/A (2024)\n",
      "  Authors: Ye Liu, Huifang Li, Chao Hu, Shuang Luo, Yan Luo, Chang Wen Chen\n",
      "  Top Concepts: Computer science, Pyramid (geometry), Context (archaeology)\n",
      "  Cited By: 33\n",
      "  OpenAlex ID: https://openalex.org/W4391130239\n",
      "\n",
      "--- Processing DOI: 10.1016/j.esci.2024.100281 ---\n",
      "  Title: Heterogeneous structure design for stable Li/Na metal batteries: Progress and prospects\n",
      "  Journal: N/A (2024)\n",
      "  Authors: Hongyang Chen, Junxiong Wu, Manxian Li, Jingyue Zhao, Zulin Li, Manxi Wang, Xuan Li, Chuanping Li, Xiaochuan Chen, Xiaoyan Li, Yiu‐Wing Mai, Yuming Chen\n",
      "  Top Concepts: Battery (electricity), Rational design, Deposition (geology)\n",
      "  Cited By: 29\n",
      "  OpenAlex ID: https://openalex.org/W4398247259\n",
      "\n",
      "--- Processing DOI: 10.1109/TEVC.2023.3278132 ---\n",
      "  Title: Knowledge Learning for Evolutionary Computation\n",
      "  Journal: N/A (2023)\n",
      "  Authors: Yi Jiang, Zhi‐Hui Zhan, Kay Chen Tan, Jun Zhang\n",
      "  Top Concepts: Computer science, Evolutionary computation, Artificial intelligence\n",
      "  Cited By: 27\n",
      "  OpenAlex ID: https://openalex.org/W4381983181\n",
      "\n",
      "--- Finished Querying ---\n",
      "\n",
      "Successfully retrieved data for 5 out of 5 DOIs.\n",
      "\n",
      "Example - Title of first result: Artificial Intelligence in Hospitality and Tourism: Insights From Industry Practices, Research Literature, and Expert Opinions\n",
      "\n",
      "Example - Authors/Institutions of second result:\n",
      "  - Shijie Zhang (Henan University of Technology)\n",
      "  - Jiajun Zheng (Henan University of Technology)\n",
      "  - Di Lan (Hubei University of Automotive Technology)\n",
      "  - Zhenguo Gao (Qingdao University, Hong Kong Polytechnic University)\n",
      "  - Xiaowei Liang (Henan University of Technology)\n",
      "  - Qingfeng Tian (Henan University of Technology)\n",
      "  - Zhiwei Zhao (Henan University of Technology)\n",
      "  - Guanglei Wu (Qingdao University)\n"
     ]
    }
   ],
   "source": [
    "## Test run\n",
    "import pyalex\n",
    "from pyalex import Works\n",
    "\n",
    "# Optional: Set your email for the OpenAlex polite pool\n",
    "pyalex.config.email = \"bennis.yiu@connect.polyu.hk\"\n",
    "\n",
    "# List of DOIs to query\n",
    "dois_to_query = [\n",
    "    \"10.1177/10963480241229235\",\n",
    "    \"10.1002/adfm.202413884\",\n",
    "    \"10.1109/TNNLS.2023.3336563\",\n",
    "    \"10.1016/j.esci.2024.100281\",\n",
    "    \"10.1109/TEVC.2023.3278132\"\n",
    "]\n",
    "\n",
    "def get_openalex_data_for_dois(doi_list):\n",
    "    \"\"\"\n",
    "    Retrieves publication data from OpenAlex for a list of DOIs.\n",
    "\n",
    "    Args:\n",
    "        doi_list: A list of DOI strings.\n",
    "\n",
    "    Returns:\n",
    "        A list of dictionaries, where each dictionary contains\n",
    "        information for a successfully found DOI. Returns an empty\n",
    "        list if no data is found or an error occurs.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    print(f\"Querying OpenAlex for {len(doi_list)} DOIs...\")\n",
    "\n",
    "    for doi in doi_list:\n",
    "        print(f\"\\n--- Processing DOI: {doi} ---\")\n",
    "        try:\n",
    "            # Construct the full DOI URL for querying\n",
    "            # pyalex often works better with the full URL format\n",
    "            full_doi_url = f\"https://doi.org/{doi.lower()}\" # Lowercase is good practice\n",
    "\n",
    "            # Query OpenAlex Works endpoint by DOI\n",
    "            work = Works()[full_doi_url] # Using dict-like access requires the full URL\n",
    "\n",
    "            if not work:\n",
    "                print(f\"  DOI not found in OpenAlex: {doi}\")\n",
    "                continue\n",
    "\n",
    "            # --- Extract desired information ---\n",
    "            # Basic Info\n",
    "            title = work.get('title', 'N/A')\n",
    "            pub_year = work.get('publication_year', 'N/A')\n",
    "            openalex_id = work.get('id', 'N/A')\n",
    "            cited_by_count = work.get('cited_by_count', 0)\n",
    "            journal_name = work.get('host_venue', {}).get('display_name', 'N/A')\n",
    "            journal_issn = work.get('host_venue', {}).get('issn_l', 'N/A') # Linking ISSN\n",
    "\n",
    "            # Authors and Affiliations\n",
    "            authors_info = []\n",
    "            if work.get('authorships'):\n",
    "                for authorship in work['authorships']:\n",
    "                    author_name = authorship.get('author', {}).get('display_name', 'N/A')\n",
    "                    author_orcid = authorship.get('author', {}).get('orcid') # Might be None\n",
    "                    institutions = authorship.get('institutions', [])\n",
    "                    institution_names = [inst.get('display_name', 'N/A') for inst in institutions]\n",
    "                    authors_info.append({\n",
    "                        \"name\": author_name,\n",
    "                        \"orcid\": author_orcid,\n",
    "                        \"institutions\": institution_names\n",
    "                    })\n",
    "\n",
    "            # Concepts (Topics/Subjects) - Let's take the top 3\n",
    "            concepts_info = []\n",
    "            if work.get('concepts'):\n",
    "                # Sort concepts by score (descending) and take top 3\n",
    "                sorted_concepts = sorted(work['concepts'], key=lambda x: x.get('score', 0), reverse=True)\n",
    "                for concept in sorted_concepts[:3]:\n",
    "                    concepts_info.append({\n",
    "                        \"name\": concept.get('display_name', 'N/A'),\n",
    "                        \"level\": concept.get('level', 'N/A'),\n",
    "                        \"score\": concept.get('score', 'N/A')\n",
    "                    })\n",
    "\n",
    "            # Store extracted data\n",
    "            extracted_data = {\n",
    "                \"doi\": doi,\n",
    "                \"openalex_id\": openalex_id,\n",
    "                \"title\": title,\n",
    "                \"publication_year\": pub_year,\n",
    "                \"cited_by_count\": cited_by_count,\n",
    "                \"journal\": journal_name,\n",
    "                \"journal_issn_l\": journal_issn,\n",
    "                \"authors\": authors_info,\n",
    "                \"concepts\": concepts_info,\n",
    "                # Add more fields here if needed by exploring the 'work' object\n",
    "                # e.g., 'type', 'abstract_inverted_index', 'referenced_works', 'related_works'\n",
    "            }\n",
    "            results.append(extracted_data)\n",
    "\n",
    "            # --- Print some key retrieved info ---\n",
    "            print(f\"  Title: {title}\")\n",
    "            print(f\"  Journal: {journal_name} ({pub_year})\")\n",
    "            print(f\"  Authors: {', '.join([a['name'] for a in authors_info])}\")\n",
    "            print(f\"  Top Concepts: {', '.join([c['name'] for c in concepts_info])}\")\n",
    "            print(f\"  Cited By: {cited_by_count}\")\n",
    "            print(f\"  OpenAlex ID: {openalex_id}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing DOI {doi}: {e}\")\n",
    "            # This could be a network error, API error, or the DOI truly not existing\n",
    "\n",
    "    print(\"\\n--- Finished Querying ---\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the function with the list of DOIs\n",
    "    retrieved_data = get_openalex_data_for_dois(dois_to_query)\n",
    "\n",
    "    # You can now work with the 'retrieved_data' list, which contains\n",
    "    # dictionaries of information for each successfully processed DOI.\n",
    "    print(f\"\\nSuccessfully retrieved data for {len(retrieved_data)} out of {len(dois_to_query)} DOIs.\")\n",
    "\n",
    "    # Example: Print the title of the first result if available\n",
    "    if retrieved_data:\n",
    "        print(f\"\\nExample - Title of first result: {retrieved_data[0].get('title', 'N/A')}\")\n",
    "\n",
    "    # Example: Print author names and institutions for the second result if available\n",
    "    if len(retrieved_data) > 1:\n",
    "        print(\"\\nExample - Authors/Institutions of second result:\")\n",
    "        for author_info in retrieved_data[1].get('authors', []):\n",
    "            print(f\"  - {author_info['name']} ({', '.join(author_info['institutions'])})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'doi': '10.1177/10963480241229235',\n",
       "  'openalex_id': 'https://openalex.org/W4391822953',\n",
       "  'title': 'Artificial Intelligence in Hospitality and Tourism: Insights From Industry Practices, Research Literature, and Expert Opinions',\n",
       "  'publication_year': 2024,\n",
       "  'cited_by_count': 30,\n",
       "  'journal': 'N/A',\n",
       "  'journal_issn_l': 'N/A',\n",
       "  'authors': [{'name': 'Hyunsu Kim',\n",
       "    'orcid': 'https://orcid.org/0000-0003-0103-9313',\n",
       "    'institutions': ['California State University, Fullerton']},\n",
       "   {'name': 'Kevin Kam Fung So',\n",
       "    'orcid': 'https://orcid.org/0000-0002-4846-7481',\n",
       "    'institutions': ['Oklahoma State University', 'Kyung Hee University']},\n",
       "   {'name': 'Seunghun Shin',\n",
       "    'orcid': 'https://orcid.org/0000-0001-7022-6732',\n",
       "    'institutions': ['Hong Kong Polytechnic University']},\n",
       "   {'name': 'Jing Li',\n",
       "    'orcid': 'https://orcid.org/0000-0003-3621-0838',\n",
       "    'institutions': ['Texas Tech University']}],\n",
       "  'concepts': [{'name': 'Hospitality', 'level': 3, 'score': 0.8348868},\n",
       "   {'name': 'Tourism', 'level': 2, 'score': 0.8121532},\n",
       "   {'name': 'Hospitality industry', 'level': 3, 'score': 0.68744355}]},\n",
       " {'doi': '10.1002/adfm.202413884',\n",
       "  'openalex_id': 'https://openalex.org/W4403192979',\n",
       "  'title': 'Hierarchical Engineering on Built‐In Electric Field of Bimetallic Zeolitic Imidazolate Derivatives Towards Amplified Dielectric Loss',\n",
       "  'publication_year': 2024,\n",
       "  'cited_by_count': 26,\n",
       "  'journal': 'N/A',\n",
       "  'journal_issn_l': 'N/A',\n",
       "  'authors': [{'name': 'Shijie Zhang',\n",
       "    'orcid': 'https://orcid.org/0000-0002-9269-5406',\n",
       "    'institutions': ['Henan University of Technology']},\n",
       "   {'name': 'Jiajun Zheng',\n",
       "    'orcid': 'https://orcid.org/0000-0001-7292-2678',\n",
       "    'institutions': ['Henan University of Technology']},\n",
       "   {'name': 'Di Lan',\n",
       "    'orcid': 'https://orcid.org/0000-0001-8570-4450',\n",
       "    'institutions': ['Hubei University of Automotive Technology']},\n",
       "   {'name': 'Zhenguo Gao',\n",
       "    'orcid': 'https://orcid.org/0000-0002-5953-1514',\n",
       "    'institutions': ['Qingdao University',\n",
       "     'Hong Kong Polytechnic University']},\n",
       "   {'name': 'Xiaowei Liang',\n",
       "    'orcid': None,\n",
       "    'institutions': ['Henan University of Technology']},\n",
       "   {'name': 'Qingfeng Tian',\n",
       "    'orcid': None,\n",
       "    'institutions': ['Henan University of Technology']},\n",
       "   {'name': 'Zhiwei Zhao',\n",
       "    'orcid': None,\n",
       "    'institutions': ['Henan University of Technology']},\n",
       "   {'name': 'Guanglei Wu',\n",
       "    'orcid': 'https://orcid.org/0000-0001-6145-3415',\n",
       "    'institutions': ['Qingdao University']}],\n",
       "  'concepts': [{'name': 'Materials science', 'level': 0, 'score': 0.8805107},\n",
       "   {'name': 'Bimetallic strip', 'level': 3, 'score': 0.86678255},\n",
       "   {'name': 'Zeolitic imidazolate framework',\n",
       "    'level': 4,\n",
       "    'score': 0.79701996}]},\n",
       " {'doi': '10.1109/TNNLS.2023.3336563',\n",
       "  'openalex_id': 'https://openalex.org/W4391130239',\n",
       "  'title': 'Learning to Aggregate Multi-Scale Context for Instance Segmentation in Remote Sensing Images',\n",
       "  'publication_year': 2024,\n",
       "  'cited_by_count': 33,\n",
       "  'journal': 'N/A',\n",
       "  'journal_issn_l': 'N/A',\n",
       "  'authors': [{'name': 'Ye Liu',\n",
       "    'orcid': 'https://orcid.org/0000-0001-9597-0525',\n",
       "    'institutions': ['Wuhan University', 'Hong Kong Polytechnic University']},\n",
       "   {'name': 'Huifang Li',\n",
       "    'orcid': 'https://orcid.org/0000-0003-4626-7416',\n",
       "    'institutions': ['Wuhan University']},\n",
       "   {'name': 'Chao Hu',\n",
       "    'orcid': 'https://orcid.org/0000-0001-6183-9051',\n",
       "    'institutions': ['Wuhan University']},\n",
       "   {'name': 'Shuang Luo',\n",
       "    'orcid': 'https://orcid.org/0000-0003-3832-0475',\n",
       "    'institutions': ['Jiangsu Changjiang Electronics Technology (China)']},\n",
       "   {'name': 'Yan Luo',\n",
       "    'orcid': 'https://orcid.org/0000-0002-9533-6070',\n",
       "    'institutions': ['Hong Kong Polytechnic University']},\n",
       "   {'name': 'Chang Wen Chen',\n",
       "    'orcid': 'https://orcid.org/0000-0002-6720-234X',\n",
       "    'institutions': ['Hong Kong Polytechnic University',\n",
       "     'Peng Cheng Laboratory']}],\n",
       "  'concepts': [{'name': 'Computer science', 'level': 0, 'score': 0.82638764},\n",
       "   {'name': 'Pyramid (geometry)', 'level': 2, 'score': 0.7803607},\n",
       "   {'name': 'Context (archaeology)', 'level': 2, 'score': 0.6926302}]},\n",
       " {'doi': '10.1016/j.esci.2024.100281',\n",
       "  'openalex_id': 'https://openalex.org/W4398247259',\n",
       "  'title': 'Heterogeneous structure design for stable Li/Na metal batteries: Progress and prospects',\n",
       "  'publication_year': 2024,\n",
       "  'cited_by_count': 29,\n",
       "  'journal': 'N/A',\n",
       "  'journal_issn_l': 'N/A',\n",
       "  'authors': [{'name': 'Hongyang Chen',\n",
       "    'orcid': 'https://orcid.org/0000-0002-7626-0162',\n",
       "    'institutions': ['Fujian Normal University']},\n",
       "   {'name': 'Junxiong Wu',\n",
       "    'orcid': None,\n",
       "    'institutions': ['Fujian Normal University']},\n",
       "   {'name': 'Manxian Li',\n",
       "    'orcid': None,\n",
       "    'institutions': ['Fujian Normal University']},\n",
       "   {'name': 'Jingyue Zhao',\n",
       "    'orcid': None,\n",
       "    'institutions': ['Fujian Normal University']},\n",
       "   {'name': 'Zulin Li',\n",
       "    'orcid': None,\n",
       "    'institutions': ['Fujian Normal University']},\n",
       "   {'name': 'Manxi Wang',\n",
       "    'orcid': 'https://orcid.org/0000-0001-9266-8611',\n",
       "    'institutions': ['Fujian Normal University']},\n",
       "   {'name': 'Xuan Li',\n",
       "    'orcid': 'https://orcid.org/0000-0001-5066-0523',\n",
       "    'institutions': ['Fujian Normal University']},\n",
       "   {'name': 'Chuanping Li',\n",
       "    'orcid': 'https://orcid.org/0000-0002-4985-3210',\n",
       "    'institutions': ['Fujian Normal University']},\n",
       "   {'name': 'Xiaochuan Chen',\n",
       "    'orcid': 'https://orcid.org/0000-0002-5720-7657',\n",
       "    'institutions': ['Fujian Normal University']},\n",
       "   {'name': 'Xiaoyan Li',\n",
       "    'orcid': 'https://orcid.org/0000-0001-7362-7128',\n",
       "    'institutions': ['Fujian Normal University']},\n",
       "   {'name': 'Yiu‐Wing Mai',\n",
       "    'orcid': 'https://orcid.org/0000-0002-9141-2793',\n",
       "    'institutions': ['Hong Kong Polytechnic University']},\n",
       "   {'name': 'Yuming Chen',\n",
       "    'orcid': 'https://orcid.org/0000-0002-7180-9515',\n",
       "    'institutions': ['Fujian Normal University']}],\n",
       "  'concepts': [{'name': 'Battery (electricity)',\n",
       "    'level': 3,\n",
       "    'score': 0.6079239},\n",
       "   {'name': 'Rational design', 'level': 2, 'score': 0.6068746},\n",
       "   {'name': 'Deposition (geology)', 'level': 3, 'score': 0.58796227}]},\n",
       " {'doi': '10.1109/TEVC.2023.3278132',\n",
       "  'openalex_id': 'https://openalex.org/W4381983181',\n",
       "  'title': 'Knowledge Learning for Evolutionary Computation',\n",
       "  'publication_year': 2023,\n",
       "  'cited_by_count': 27,\n",
       "  'journal': 'N/A',\n",
       "  'journal_issn_l': 'N/A',\n",
       "  'authors': [{'name': 'Yi Jiang',\n",
       "    'orcid': 'https://orcid.org/0000-0003-1965-0372',\n",
       "    'institutions': ['South China University of Technology']},\n",
       "   {'name': 'Zhi‐Hui Zhan',\n",
       "    'orcid': 'https://orcid.org/0000-0003-0862-0514',\n",
       "    'institutions': ['South China University of Technology']},\n",
       "   {'name': 'Kay Chen Tan',\n",
       "    'orcid': 'https://orcid.org/0000-0002-6802-2463',\n",
       "    'institutions': ['Hong Kong Polytechnic University']},\n",
       "   {'name': 'Jun Zhang',\n",
       "    'orcid': 'https://orcid.org/0000-0001-7835-9871',\n",
       "    'institutions': ['Zhejiang Normal University', 'Hanyang University']}],\n",
       "  'concepts': [{'name': 'Computer science', 'level': 0, 'score': 0.737087},\n",
       "   {'name': 'Evolutionary computation', 'level': 2, 'score': 0.69463915},\n",
       "   {'name': 'Artificial intelligence', 'level': 1, 'score': 0.67390084}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09565c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Revise version:\n",
    "\n",
    "import pyalex\n",
    "from pyalex import Works\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv\n",
    "import os  # To check if CSV exists\n",
    "\n",
    "# --- Configuration ---\n",
    "# Optional: Set your email for the OpenAlex polite pool (recommended)\n",
    "pyalex.config.email = \"bennis.yiu@connect.polyu.hk\"\n",
    "\n",
    "# Define the headers for the output CSV based on the data we plan to extract\n",
    "# This ensures consistency even if some records lack certain fields\n",
    "CSV_HEADERS = [\n",
    "    \"input_doi\", # Keep track of the DOI we queried with\n",
    "    \"openalex_id\",\n",
    "    \"title\",\n",
    "    \"publication_year\",\n",
    "    \"cited_by_count\",\n",
    "    \"journal\",\n",
    "    \"journal_issn_l\",\n",
    "    \"authors_names\", # Comma-separated string of names\n",
    "    \"authors_orcids\", # Comma-separated string of ORCIDs (or N/A)\n",
    "    \"institutions\", # Comma-separated string of unique institutions\n",
    "    \"top_concept_1_name\",\n",
    "    \"top_concept_1_level\",\n",
    "    \"top_concept_1_score\",\n",
    "    \"top_concept_2_name\",\n",
    "    \"top_concept_2_level\",\n",
    "    \"top_concept_2_score\",\n",
    "    \"top_concept_3_name\",\n",
    "    \"top_concept_3_level\",\n",
    "    \"top_concept_3_score\",\n",
    "    \"retrieval_status\" # Indicate success or failure for this DOI\n",
    "]\n",
    "\n",
    "def fetch_and_save_openalex_data(\n",
    "    df,\n",
    "    doi_column='prism_doi',\n",
    "    output_csv_path='openalex_results.csv',\n",
    "    max_calls=4000,\n",
    "    sleep_time=0.1 # Small delay between calls to be polite\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Retrieves publication data from OpenAlex for DOIs in a DataFrame,\n",
    "    limits API calls, and saves results incrementally to a CSV.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing DOIs.\n",
    "        doi_column (str): Name of the column containing the DOIs.\n",
    "        output_csv_path (str): Path to save the output CSV file.\n",
    "        max_calls (int): Maximum number of OpenAlex API calls for this run.\n",
    "        sleep_time (float): Seconds to wait between API calls.\n",
    "\n",
    "    Returns:\n",
    "        int: The number of DOIs successfully processed and saved in this run.\n",
    "    \"\"\"\n",
    "    if doi_column not in df.columns:\n",
    "        print(f\"Error: DOI column '{doi_column}' not found in DataFrame.\")\n",
    "        return 0\n",
    "\n",
    "    dois_to_process = df[doi_column].dropna().unique() # Get unique, non-null DOIs\n",
    "    print(f\"Found {len(dois_to_process)} unique non-null DOIs in column '{doi_column}'.\")\n",
    "\n",
    "    processed_count = 0\n",
    "    calls_made = 0\n",
    "\n",
    "    # Check if CSV exists to decide whether to write headers\n",
    "    file_exists = os.path.isfile(output_csv_path)\n",
    "\n",
    "    # Open CSV file in append mode ('a')\n",
    "    # Use newline='' to prevent extra blank rows in Windows\n",
    "    # Use utf-8 encoding for broad compatibility\n",
    "    try:\n",
    "        with open(output_csv_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "            # Use DictWriter for easy writing from dictionaries\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=CSV_HEADERS)\n",
    "\n",
    "            # Write header only if the file is new\n",
    "            if not file_exists:\n",
    "                writer.writeheader()\n",
    "                print(f\"Created new output file: {output_csv_path}\")\n",
    "            else:\n",
    "                print(f\"Appending to existing file: {output_csv_path}\")\n",
    "\n",
    "            # Iterate through the unique DOIs\n",
    "            for doi in dois_to_process:\n",
    "                if calls_made >= max_calls:\n",
    "                    print(f\"\\nReached maximum API calls limit ({max_calls}). Stopping.\")\n",
    "                    break\n",
    "\n",
    "                if not isinstance(doi, str) or not doi.strip():\n",
    "                    print(f\"Skipping invalid DOI value: {doi}\")\n",
    "                    continue\n",
    "\n",
    "                doi_cleaned = doi.strip().lower() # Clean and normalize DOI\n",
    "                print(f\"\\n--- Processing DOI ({calls_made + 1}/{max_calls}): {doi_cleaned} ---\")\n",
    "\n",
    "                calls_made += 1\n",
    "                extracted_data = {header: 'N/A' for header in CSV_HEADERS} # Initialize with defaults\n",
    "                extracted_data[\"input_doi\"] = doi # Store the original queried DOI\n",
    "                retrieval_successful = False\n",
    "\n",
    "                try:\n",
    "                    # Construct the full DOI URL\n",
    "                    full_doi_url = f\"https://doi.org/{doi_cleaned}\"\n",
    "\n",
    "                    # Query OpenAlex Works endpoint by DOI\n",
    "                    work = Works()[full_doi_url]\n",
    "                    time.sleep(sleep_time) # Pause before next potential call\n",
    "\n",
    "                    if work and work.get('id'): # Check if a valid work object was returned\n",
    "                        # --- Extract desired information ---\n",
    "                        extracted_data[\"openalex_id\"] = work.get('id', 'N/A')\n",
    "                        extracted_data[\"title\"] = work.get('title', 'N/A')\n",
    "                        extracted_data[\"publication_year\"] = work.get('publication_year', 'N/A')\n",
    "                        extracted_data[\"cited_by_count\"] = work.get('cited_by_count', 0)\n",
    "                        extracted_data[\"journal\"] = work.get('host_venue', {}).get('display_name', 'N/A')\n",
    "                        extracted_data[\"journal_issn_l\"] = work.get('host_venue', {}).get('issn_l', 'N/A')\n",
    "\n",
    "                        # Authors and Affiliations\n",
    "                        author_names = []\n",
    "                        author_orcids = []\n",
    "                        all_institutions = set() # Use a set to store unique institution names\n",
    "                        if work.get('authorships'):\n",
    "                            for authorship in work['authorships']:\n",
    "                                author_names.append(authorship.get('author', {}).get('display_name', 'N/A'))\n",
    "                                author_orcids.append(authorship.get('author', {}).get('orcid', 'N/A') or 'N/A') # Handle None ORCID\n",
    "                                institutions = authorship.get('institutions', [])\n",
    "                                for inst in institutions:\n",
    "                                    inst_name = inst.get('display_name', 'N/A')\n",
    "                                    if inst_name != 'N/A':\n",
    "                                        all_institutions.add(inst_name)\n",
    "\n",
    "                        extracted_data[\"authors_names\"] = \", \".join(author_names)\n",
    "                        extracted_data[\"authors_orcids\"] = \", \".join(author_orcids)\n",
    "                        extracted_data[\"institutions\"] = \", \".join(sorted(list(all_institutions)))\n",
    "\n",
    "                        # Concepts (Top 3)\n",
    "                        if work.get('concepts'):\n",
    "                            sorted_concepts = sorted(work['concepts'], key=lambda x: x.get('score', 0), reverse=True)\n",
    "                            for i, concept in enumerate(sorted_concepts[:3]):\n",
    "                                extracted_data[f\"top_concept_{i+1}_name\"] = concept.get('display_name', 'N/A')\n",
    "                                extracted_data[f\"top_concept_{i+1}_level\"] = concept.get('level', 'N/A')\n",
    "                                extracted_data[f\"top_concept_{i+1}_score\"] = concept.get('score', 'N/A')\n",
    "\n",
    "                        print(f\"  Success: Found data for {doi_cleaned}\")\n",
    "                        extracted_data[\"retrieval_status\"] = \"Success\"\n",
    "                        retrieval_successful = True\n",
    "                        processed_count += 1\n",
    "\n",
    "                    else:\n",
    "                        print(f\"  Failed: DOI not found or no data in OpenAlex: {doi_cleaned}\")\n",
    "                        extracted_data[\"retrieval_status\"] = \"Failed - Not Found\"\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"  Error processing DOI {doi_cleaned}: {e}\")\n",
    "                    extracted_data[\"retrieval_status\"] = f\"Failed - Error: {type(e).__name__}\"\n",
    "                    # Optional: Add a longer sleep after an error\n",
    "                    # time.sleep(1)\n",
    "\n",
    "                # Write the row to CSV regardless of success/failure, using the status field\n",
    "                writer.writerow(extracted_data)\n",
    "                csvfile.flush() # Ensure data is written to disk periodically\n",
    "\n",
    "    except IOError as e:\n",
    "        print(f\"Error opening or writing to CSV file {output_csv_path}: {e}\")\n",
    "        return 0 # Indicate failure to write\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during processing: {e}\")\n",
    "        return processed_count # Return count up to the point of failure\n",
    "\n",
    "    print(f\"\\n--- Finished Run ---\")\n",
    "    print(f\"Total API calls made in this run: {calls_made}\")\n",
    "    print(f\"DOIs successfully processed and saved in this run: {processed_count}\")\n",
    "    print(f\"Results saved to: {output_csv_path}\")\n",
    "\n",
    "    return processed_count\n",
    "\n",
    "\n",
    "# --- Main execution ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # --- 1. Load your Scopus data ---\n",
    "    # Replace 'your_scopus_data.csv' with the actual path to your file\n",
    "    scopus_data_path = 'your_scopus_data.csv'\n",
    "    output_file = 'openalex_enhanced_data.csv'\n",
    "    doi_col_name = 'prism_doi' # The name of the DOI column in your Scopus file\n",
    "    api_limit = 4000 # Set your desired limit per run\n",
    "\n",
    "    try:\n",
    "        print(f\"Loading Scopus data from: {scopus_data_path}\")\n",
    "        input_df = pd.read_csv(scopus_data_path)\n",
    "        print(f\"Loaded {len(input_df)} rows.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file not found at {scopus_data_path}\")\n",
    "        # Example: Create a dummy DataFrame for testing if file not found\n",
    "        print(\"Creating a dummy DataFrame for testing.\")\n",
    "        input_df = pd.DataFrame({\n",
    "            'prism_doi': [\n",
    "                \"10.1177/10963480241229235\",\n",
    "                \"10.1002/adfm.202413884\",\n",
    "                \"10.1109/TNNLS.2023.3336563\",\n",
    "                \"10.1016/j.esci.2024.100281\",\n",
    "                \"10.1109/TEVC.2023.3278132\",\n",
    "                \"invalid_doi\", # Example of an invalid DOI\n",
    "                None, # Example of a missing DOI\n",
    "                \"10.1000/nodata_doi\", # Example of a DOI potentially not in OpenAlex\n",
    "            ],\n",
    "            'other_scopus_data': range(8)\n",
    "        })\n",
    "        doi_col_name = 'prism_doi' # Ensure this matches the dummy frame\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV: {e}\")\n",
    "        exit() # Exit if we can't load the data\n",
    "\n",
    "    # --- 2. Fetch data from OpenAlex and save to CSV ---\n",
    "    successfully_processed = fetch_and_save_openalex_data(\n",
    "        df=input_df,\n",
    "        doi_column=doi_col_name,\n",
    "        output_csv_path=output_file,\n",
    "        max_calls=api_limit\n",
    "    )\n",
    "\n",
    "    # --- 3. Load the results from the CSV into a DataFrame ---\n",
    "    if successfully_processed > 0 or os.path.isfile(output_file):\n",
    "        try:\n",
    "            print(f\"\\nLoading results from {output_file} into a DataFrame...\")\n",
    "            results_df = pd.read_csv(output_file)\n",
    "            print(f\"Successfully loaded {len(results_df)} rows from the CSV.\")\n",
    "            print(\"\\nFirst 5 rows of the results DataFrame:\")\n",
    "            print(results_df.head())\n",
    "\n",
    "            # You can now work with results_df\n",
    "            # For example, merge it back with your original Scopus data if needed:\n",
    "            # merged_df = pd.merge(input_df, results_df, left_on=doi_col_name, right_on='input_doi', how='left')\n",
    "            # print(\"\\nPreview of merged data:\")\n",
    "            # print(merged_df.head())\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Output file {output_file} not found after processing. Cannot load DataFrame.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading results CSV into DataFrame: {e}\")\n",
    "    else:\n",
    "        print(\"\\nNo new data was processed or saved, skipping loading results DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f48be7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf60b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b4108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a6b7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

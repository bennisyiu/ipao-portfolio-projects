{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969bd08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./myenv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (2.32.3)\n",
      "Requirement already satisfied: pandas in ./myenv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.2.3)\n",
      "Requirement already satisfied: psycopg2-binary in ./myenv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.9.10)\n",
      "Requirement already satisfied: python-dotenv in ./myenv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (1.1.0)\n",
      "Requirement already satisfied: numpy in ./myenv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (2.2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./myenv/lib/python3.12/site-packages (from requests->-r requirements.txt (line 2)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./myenv/lib/python3.12/site-packages (from requests->-r requirements.txt (line 2)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./myenv/lib/python3.12/site-packages (from requests->-r requirements.txt (line 2)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./myenv/lib/python3.12/site-packages (from requests->-r requirements.txt (line 2)) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./myenv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./myenv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./myenv/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 3)) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./myenv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5437eed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import pytz\n",
    "import psycopg2\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import ast\n",
    "from datetime import timedelta, datetime\n",
    "from pandas import json_normalize\n",
    "from dotenv import load_dotenv\n",
    "from requests.exceptions import Timeout, RequestException\n",
    "from psycopg2 import sql\n",
    "from psycopg2.extras import execute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebeecb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_credentials():\n",
    "    \"\"\"Load and validate credentials from environment variables.\"\"\"\n",
    "\n",
    "    print('get_credentials() method')\n",
    "    load_dotenv()  # Load .env file\n",
    "\n",
    "    # Facebook credentials\n",
    "    scopus_api_key = os.getenv(\"SCOPUS_API_KEY\")\n",
    "    if not scopus_api_key:\n",
    "        raise ValueError(\"SCOPUS_API_KEY is missing in .env!\")\n",
    "\n",
    "    scopus_credentials = {\n",
    "        \"access_token\": scopus_api_key,\n",
    "        \"scopus_label\": os.getenv(\"SCOPUS_LABEL\")\n",
    "    }\n",
    "\n",
    "    # Database credentials\n",
    "    db_credentials = {\n",
    "        \"hostname\": os.getenv(\"DB_HOST\"),\n",
    "        \"port\": int(os.getenv(\"DB_PORT\")),  # Convert to integer\n",
    "        \"username\": os.getenv(\"DB_USER\"),\n",
    "        \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "        \"database\": os.getenv(\"DB_NAME\"),\n",
    "        \"schema\": os.getenv(\"DB_SCHEMA\")\n",
    "    }\n",
    "\n",
    "    return scopus_credentials, db_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a8598d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scopus_api_caller(url, params, headers, max_retries=3, timeout=20):\n",
    "    print('scopus_api_caller() method')\n",
    "    all_data = []\n",
    "    retry_count = 0\n",
    "\n",
    "    while url and retry_count < max_retries:\n",
    "        try:\n",
    "            print(f'Making request to URL: {url}')\n",
    "            response = requests.get(\n",
    "                url, params=params, headers=headers, timeout=timeout)\n",
    "            print(f'Response status code: {response.status_code}')\n",
    "\n",
    "            if response.status_code != 200:\n",
    "                print(f'Error response content: {response.text}')\n",
    "\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            if 'search-results' in data and 'entry' in data['search-results']:\n",
    "                all_data.extend(data['search-results']['entry'])\n",
    "                print(\n",
    "                    f\"Collected {len(data['search-results']['entry'])} items. Total: {len(all_data)}\")\n",
    "            else:\n",
    "                print(\"No data found in response\")\n",
    "                break\n",
    "\n",
    "            # Check if there are more pages\n",
    "            if 'link' in data['search-results']:\n",
    "                next_link = next(\n",
    "                    (link for link in data['search-results']['link'] if link['@ref'] == 'next'), None)\n",
    "                if next_link:\n",
    "                    url = next_link['@href']\n",
    "                    params = {}  # Clear params as they're included in the next URL\n",
    "                else:\n",
    "                    url = None\n",
    "                    print(\"No more pages\")\n",
    "            else:\n",
    "                url = None\n",
    "                print(\"No more pages\")\n",
    "\n",
    "            retry_count = 0  # Reset retry count on successful request\n",
    "\n",
    "        except (Timeout, RequestException) as e:\n",
    "            retry_count += 1\n",
    "            print(\n",
    "                f\"Request failed: {e}. Retry attempt {retry_count} of {max_retries}\")\n",
    "            if retry_count == max_retries:\n",
    "                print(\"Max retries reached. Exiting.\")\n",
    "                break\n",
    "            time.sleep(2 ** retry_count)  # Exponential backoff\n",
    "\n",
    "    print(f'Exiting scopus_api_caller. Total items collected: {len(all_data)}')\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ab5a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scopus_search(scopus_credentials, query, start=0, count=25, sort='citedby-count', max_results=5000):\n",
    "    print('scopus_search() method')\n",
    "\n",
    "    scopus_api_key = scopus_credentials['access_token']\n",
    "    url = 'https://api.elsevier.com/content/search/scopus'\n",
    "\n",
    "    headers = {\n",
    "        'X-ELS-APIKey': scopus_api_key,\n",
    "        'Accept': 'application/json'\n",
    "    }\n",
    "\n",
    "    # list of fields\n",
    "    fields = [\n",
    "        'dc:identifier',  # Unique identifier\n",
    "        'prism:doi',      # DOI for Abstract Retrieval API\n",
    "        'prism:coverDate',  # Publication date\n",
    "        'citedby-count',  # Citation count\n",
    "        'prism:publicationName',  # Journal or conference name\n",
    "        # Type of publication (e.g., Article, Conference Paper)\n",
    "        'subtypeDescription',\n",
    "    ]\n",
    "\n",
    "    params = {\n",
    "        'query': query,\n",
    "        'field': ','.join(fields),\n",
    "        'count': count,\n",
    "        'start': start,\n",
    "        'sort': sort\n",
    "    }\n",
    "\n",
    "    all_results = []\n",
    "    total_results = None\n",
    "\n",
    "    while len(all_results) < max_results:\n",
    "        print(f'Full URL: {url}')\n",
    "        print(f'Headers: {headers}')\n",
    "        print(f'Params: {params}')\n",
    "\n",
    "        # Fetch the data\n",
    "        batch_results = scopus_api_caller(url, params, headers)\n",
    "\n",
    "        if not batch_results:\n",
    "            print(\"No results returned from API. Stopping search.\")\n",
    "            break\n",
    "\n",
    "        all_results.extend(batch_results)\n",
    "\n",
    "        # Check total number of results if not already set\n",
    "        if total_results is None:\n",
    "            total_results = int(batch_results[0].get(\n",
    "                'search-results', {}).get('opensearch:totalResults', 0))\n",
    "            print(f\"Total results available: {total_results}\")\n",
    "            if total_results == 0:\n",
    "                print(\"No results found for the given query.\")\n",
    "                break\n",
    "\n",
    "        # Update start for the next page\n",
    "        params['start'] = len(all_results)\n",
    "\n",
    "        # Check if we've reached the end of results\n",
    "        if len(all_results) >= total_results or len(all_results) >= max_results:\n",
    "            print(\"All available results have been retrieved or max results reached.\")\n",
    "            break\n",
    "\n",
    "        if len(batch_results) < count:\n",
    "            print(\"Reached the end of available results.\")\n",
    "            break\n",
    "\n",
    "    print(f'{len(all_results)} of SCOPUS data will be processed.')\n",
    "\n",
    "    if not all_results:\n",
    "        print(\"No results found for the given query.\")\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25b11189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_list_item(item):\n",
    "    if isinstance(item, dict):\n",
    "        return [str(value) for value in item.values() if value]\n",
    "    elif isinstance(item, str):\n",
    "        return [item]\n",
    "    elif isinstance(item, list):\n",
    "        return [str(subitem) for subitem in item if subitem]\n",
    "    else:\n",
    "        return [str(item)] if item else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b50dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_scopus_search_results(all_data):\n",
    "    \"\"\"Process Scopus search results data\n",
    "    Return a dataframe with selected columns and database-friendly names\n",
    "    \"\"\"\n",
    "    if not all_data:\n",
    "        print(\"No data received from Scopus API\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.json_normalize(all_data)\n",
    "\n",
    "    # Function to clean column names\n",
    "    def clean_column_name(name):\n",
    "        # Replace non-alphanumeric characters with underscores\n",
    "        name = re.sub(r'[^a-zA-Z0-9]', '_', name)\n",
    "        # Replace multiple underscores with a single underscore\n",
    "        name = re.sub(r'_+', '_', name)\n",
    "        # Remove leading or trailing underscores\n",
    "        name = name.strip('_')\n",
    "        # Convert to lowercase\n",
    "        return name.lower()\n",
    "\n",
    "    # Clean column names\n",
    "    df.columns = [clean_column_name(col) for col in df.columns]\n",
    "\n",
    "    # Ensure all fields from scopus_search() are present\n",
    "    expected_fields = [\n",
    "        'dc_identifier',\n",
    "        'prism_doi',\n",
    "        'prism_coverdate',\n",
    "        'citedby_count',\n",
    "        'prism_publicationname',\n",
    "        'subtypedescription'\n",
    "    ]\n",
    "\n",
    "    for field in expected_fields:\n",
    "        if field not in df.columns:\n",
    "            df[field] = None\n",
    "            print(\n",
    "                f\"Warning: '{field}' not found in API response. Added as empty column.\")\n",
    "\n",
    "    # Convert numeric fields\n",
    "    if 'citedby_count' in df.columns:\n",
    "        df['citedby_count'] = pd.to_numeric(\n",
    "            df['citedby_count'], errors='coerce')\n",
    "\n",
    "    # Convert date fields\n",
    "    if 'prism_coverdate' in df.columns:\n",
    "        df['prism_coverdate'] = pd.to_datetime(\n",
    "            df['prism_coverdate'], errors='coerce')\n",
    "\n",
    "    # Add a column for publication year\n",
    "    if 'prism_coverdate' in df.columns:\n",
    "        df['publication_year'] = df['prism_coverdate'].dt.year\n",
    "    else:\n",
    "        print(\n",
    "            \"Warning: 'prism_coverdate' not found in the data. Using 2100 as fallback year.\")\n",
    "        df['publication_year'] = 2100\n",
    "\n",
    "    # Ensure publication_year is always an integer\n",
    "    df['publication_year'] = df['publication_year'].fillna(2100).astype(int)\n",
    "\n",
    "    # Print column names and their types for debugging\n",
    "    print(\"Column names and types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    # Print the first few rows for debugging\n",
    "    print(\"First few rows of the processed dataframe:\")\n",
    "    print(df.head())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f457d2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_existing_results(new_results, existing_df):\n",
    "    if existing_df.empty:\n",
    "        return new_results\n",
    "\n",
    "    existing_ids = set(existing_df['dc_identifier'].tolist())\n",
    "    return [result for result in new_results if result.get('dc:identifier') not in existing_ids]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b856029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scopus_research_procedures(years_to_process):\n",
    "    try:\n",
    "        scopus_credentials, db_credentials = get_credentials()  # pylint: disable=unused-variable\n",
    "\n",
    "        max_results_per_api_call = 5000\n",
    "\n",
    "        csv_file = 'polyu_research_output.csv'\n",
    "        existing_df = pd.DataFrame()\n",
    "        try:\n",
    "            existing_df = pd.read_csv(csv_file)\n",
    "            if 'publication_year' not in existing_df.columns:\n",
    "                print(\"Adding missing publication_year column to existing data\")\n",
    "                existing_df['publication_year'] = pd.to_datetime(existing_df['prism_coverdate']).dt.year\n",
    "            print(f\"Loaded {len(existing_df)} existing records from {csv_file}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"No existing file found at {csv_file}. Starting fresh.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV file: {e}\")\n",
    "\n",
    "        all_new_results = []\n",
    "        latest_df = existing_df.copy()  # Initialize latest_df with existing data\n",
    "\n",
    "        for year in years_to_process:\n",
    "            query = f\"AFFIL(\\\"The Hong Kong Polytechnic University\\\") AND PUBYEAR = {year}\"\n",
    "            print(f\"\\nExecuting Scopus search with query: {query}\")\n",
    "\n",
    "            year_results = []\n",
    "            start = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    polyu_results = scopus_search(\n",
    "                        scopus_credentials, query, start=start, max_results=max_results_per_api_call)\n",
    "\n",
    "                    if not polyu_results:\n",
    "                        print(f\"No more results found for {year}.\")\n",
    "                        break\n",
    "\n",
    "                    year_results.extend(polyu_results)\n",
    "                    start += len(polyu_results)\n",
    "\n",
    "                    print(f\"Retrieved {len(polyu_results)} results for {year}. Total for {year}: {len(year_results)}\")\n",
    "\n",
    "                    if len(polyu_results) < max_results_per_api_call:\n",
    "                        print(f\"Reached the end of available results for {year}.\")\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during API call: {e}\")\n",
    "                    print(\"Saving current results and moving to next year.\")\n",
    "                    break\n",
    "\n",
    "            # Process and save results for this year\n",
    "            if year_results:\n",
    "                try:\n",
    "                    new_df = process_scopus_search_results(year_results)\n",
    "                    if 'publication_year' not in new_df.columns:\n",
    "                        # Ensure publication_year is added\n",
    "                        new_df['publication_year'] = year\n",
    "\n",
    "                    # Combine with existing data\n",
    "                    latest_df = pd.concat([latest_df, new_df], ignore_index=True)\n",
    "                    latest_df.drop_duplicates(subset='dc_identifier', keep='last', inplace=True)\n",
    "\n",
    "                    # Try to save the results to a CSV file\n",
    "                    try:\n",
    "                        latest_df.to_csv(csv_file, index=False)\n",
    "                        print(f\"\\nResults saved to '{csv_file}'. Total records: {len(latest_df)}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error saving CSV file: {e}\")\n",
    "                        print(\"Continuing with in-memory DataFrame.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing results for {year}: {e}\")\n",
    "\n",
    "            all_new_results.extend(year_results)\n",
    "\n",
    "        if not all_new_results:\n",
    "            print(\"No new results to process across all years.\")\n",
    "        else:\n",
    "            print(f\"Total new results across all years: {len(all_new_results)}\")\n",
    "\n",
    "        return latest_df  # Return the latest DataFrame\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of overall failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df = scopus_research_procedures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cefd04c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e00c6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## revised scopus_research_procedures function to exclude existing results\n",
    "\n",
    "def scopus_research_procedures(years_to_process):\n",
    "    try:\n",
    "        scopus_credentials, _ = get_credentials()\n",
    "\n",
    "        max_results_per_api_call = 5000\n",
    "\n",
    "        csv_file = 'polyu_research_output.csv'\n",
    "        metadata_file = 'scopus_search_metadata.json'\n",
    "        \n",
    "        # Load or initialize metadata\n",
    "        try:\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            metadata = {}\n",
    "\n",
    "        existing_df = pd.DataFrame()\n",
    "        try:\n",
    "            existing_df = pd.read_csv(csv_file)\n",
    "            if 'publication_year' not in existing_df.columns:\n",
    "                print(\"Adding missing publication_year column to existing data\")\n",
    "                existing_df['publication_year'] = pd.to_datetime(existing_df['prism_coverdate']).dt.year\n",
    "            print(f\"Loaded {len(existing_df)} existing records from {csv_file}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"No existing file found at {csv_file}. Starting fresh.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV file: {e}\")\n",
    "\n",
    "        all_new_results = []\n",
    "        latest_df = existing_df.copy()  # Initialize latest_df with existing data\n",
    "\n",
    "        for year in years_to_process:\n",
    "            query = f\"AFFIL(\\\"The Hong Kong Polytechnic University\\\") AND PUBYEAR = {year}\"\n",
    "            print(f\"\\nExecuting Scopus search with query: {query}\")\n",
    "\n",
    "            year_results = []\n",
    "            start = metadata.get(str(year), {}).get('last_start', 0)\n",
    "            while True:\n",
    "                try:\n",
    "                    polyu_results = scopus_search(\n",
    "                        scopus_credentials, query, start=start, max_results=max_results_per_api_call)\n",
    "\n",
    "                    if not polyu_results:\n",
    "                        print(f\"No more results found for {year}.\")\n",
    "                        break\n",
    "\n",
    "                    year_results.extend(polyu_results)\n",
    "                    start += len(polyu_results)\n",
    "\n",
    "                    print(f\"Retrieved {len(polyu_results)} results for {year}. Total for {year}: {len(year_results)}\")\n",
    "\n",
    "                    if len(polyu_results) < max_results_per_api_call:\n",
    "                        print(f\"Reached the end of available results for {year}.\")\n",
    "                        break\n",
    "\n",
    "                    # Update metadata\n",
    "                    metadata[str(year)] = {'last_start': start}\n",
    "                    with open(metadata_file, 'w') as f:\n",
    "                        json.dump(metadata, f)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during API call: {e}\")\n",
    "                    print(\"Saving current results and moving to next year.\")\n",
    "                    break\n",
    "\n",
    "            # Process and save results for this year\n",
    "            if year_results:\n",
    "                try:\n",
    "                    new_df = process_scopus_search_results(year_results)\n",
    "                    if 'publication_year' not in new_df.columns:\n",
    "                        # Ensure publication_year is added\n",
    "                        new_df['publication_year'] = year\n",
    "\n",
    "                    # Combine with existing data\n",
    "                    latest_df = pd.concat([latest_df, new_df], ignore_index=True)\n",
    "                    latest_df.drop_duplicates(subset='dc_identifier', keep='last', inplace=True)\n",
    "\n",
    "                    # Try to save the results to a CSV file\n",
    "                    try:\n",
    "                        latest_df.to_csv(csv_file, index=False)\n",
    "                        print(f\"\\nResults saved to '{csv_file}'. Total records: {len(latest_df)}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error saving CSV file: {e}\")\n",
    "                        print(\"Continuing with in-memory DataFrame.\")\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing results for {year}: {e}\")\n",
    "\n",
    "            all_new_results.extend(year_results)\n",
    "\n",
    "        if not all_new_results:\n",
    "            print(\"No new results to process across all years.\")\n",
    "        else:\n",
    "            print(f\"Total new results across all years: {len(all_new_results)}\")\n",
    "\n",
    "        return latest_df  # Return the latest DataFrame\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of overall failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d4f8db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3rd revised scopus_research_procedures function to handle results beyond 5000 limit:\n",
    "\n",
    "def scopus_research_procedures(years_to_process):\n",
    "    try:\n",
    "        scopus_credentials, _ = get_credentials()  \n",
    "\n",
    "        max_results_per_api_call = 5000\n",
    "\n",
    "        csv_file = 'polyu_research_output.csv'\n",
    "        metadata_file = 'scopus_search_metadata.json'\n",
    "        \n",
    "        # Load or initialize metadata\n",
    "        try:\n",
    "            with open(metadata_file, 'r') as f:\n",
    "                metadata = json.load(f)\n",
    "        except FileNotFoundError:\n",
    "            metadata = {}\n",
    "\n",
    "        existing_df = pd.DataFrame()\n",
    "        try:\n",
    "            existing_df = pd.read_csv(csv_file)\n",
    "            if 'publication_year' not in existing_df.columns:\n",
    "                print(\"Adding missing publication_year column to existing data\")\n",
    "                existing_df['publication_year'] = pd.to_datetime(existing_df['prism_coverdate']).dt.year\n",
    "            print(f\"Loaded {len(existing_df)} existing records from {csv_file}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"No existing file found at {csv_file}. Starting fresh.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading CSV file: {e}\")\n",
    "\n",
    "        latest_df = existing_df.copy()  # Initialize latest_df with existing data\n",
    "\n",
    "        for year in years_to_process:\n",
    "            query = f\"AFFIL(\\\"The Hong Kong Polytechnic University\\\") AND PUBYEAR = {year}\"\n",
    "            print(f\"\\nExecuting Scopus search with query: {query}\")\n",
    "\n",
    "            start = metadata.get(str(year), {}).get('last_start', 0)\n",
    "            total_results = metadata.get(str(year), {}).get('total_results', None)\n",
    "            \n",
    "            while True:\n",
    "                try:\n",
    "                    polyu_results = scopus_search(\n",
    "                        scopus_credentials, query, start=start, max_results=max_results_per_api_call)\n",
    "\n",
    "                    if not polyu_results:\n",
    "                        print(f\"No more results found for {year}.\")\n",
    "                        break\n",
    "\n",
    "                    # Process new results\n",
    "                    new_df = process_scopus_search_results(polyu_results)\n",
    "                    if 'publication_year' not in new_df.columns:\n",
    "                        new_df['publication_year'] = year\n",
    "\n",
    "                    # Exclude existing results\n",
    "                    new_df = new_df[~new_df['dc_identifier'].isin(latest_df['dc_identifier'])]\n",
    "\n",
    "                    # Append new results to latest_df\n",
    "                    latest_df = pd.concat([latest_df, new_df], ignore_index=True)\n",
    "\n",
    "                    start += len(polyu_results)\n",
    "                    print(f\"Retrieved {len(polyu_results)} new results for {year}. Total for {year}: {len(latest_df[latest_df['publication_year'] == year])}\")\n",
    "\n",
    "                    # Update total_results if not set\n",
    "                    if total_results is None:\n",
    "                        total_results = int(polyu_results[0].get('search-results', {}).get('opensearch:totalResults', 0))\n",
    "                        print(f\"Total results available for {year}: {total_results}\")\n",
    "\n",
    "                    # Update metadata\n",
    "                    metadata[str(year)] = {'last_start': start, 'total_results': total_results}\n",
    "                    with open(metadata_file, 'w') as f:\n",
    "                        json.dump(metadata, f)\n",
    "\n",
    "                    # Save results to CSV file\n",
    "                    latest_df.to_csv(csv_file, index=False)\n",
    "                    print(f\"\\nResults saved to '{csv_file}'. Total records: {len(latest_df)}\")\n",
    "\n",
    "                    if start >= total_results:\n",
    "                        print(f\"Reached the end of available results for {year}.\")\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during API call: {e}\")\n",
    "                    print(\"Saving current results and moving to next year.\")\n",
    "                    break\n",
    "\n",
    "        print(f\"Total records across all years: {len(latest_df)}\")\n",
    "        return latest_df  # Return the latest DataFrame\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of overall failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(df1, df2):\n",
    "    # Assuming 'dc_identifier' is the unique identifier for each record\n",
    "    duplicates = df1[df1['dc_identifier'].isin(df2['dc_identifier'])]\n",
    "    print(f\"Number of duplicate records: {len(duplicates)}\")\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "855f8bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_credentials() method\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'access_token': '79f2bcb9937cc0efa767b7e1b6da3055',\n",
       "  'scopus_label': 'bennisSCOPUSKey'},\n",
       " {'hostname': 'portfolio-projects.ctoiwe860cq9.ap-southeast-1.rds.amazonaws.com',\n",
       "  'port': 5432,\n",
       "  'username': 'bennisyiu',\n",
       "  'password': 'Yatpatyeh234',\n",
       "  'database': 'postgres',\n",
       "  'schema': 'public'})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scopus_credentials, db_credentials = get_credentials()  \n",
    "scopus_credentials, db_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba23375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Credentials: {'hostname': 'portfolio-projects.ctoiwe860cq9.ap-southeast-1.rds.amazonaws.com', 'port': 5432, 'username': 'bennisyiu', 'password': 'Yatpatyeh234', 'database': 'postgres'}\n"
     ]
    }
   ],
   "source": [
    "# load_dotenv()\n",
    "\n",
    "# # Access the credentials\n",
    "# db_credentials = {\n",
    "#     'hostname': os.getenv('DB_HOST'),\n",
    "#     'port': int(os.getenv('DB_PORT', 5432)),  # Default to 5432 if not specified\n",
    "#     'username': os.getenv('DB_USER'),\n",
    "#     'password': os.getenv('DB_PASSWORD'),\n",
    "#     'database': os.getenv('DB_NAME')\n",
    "# }\n",
    "\n",
    "# # Debugging: Print the credentials (ensure they are loaded correctly)\n",
    "# print(\"Database Credentials:\", db_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abc061b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hostname': 'portfolio-projects.ctoiwe860cq9.ap-southeast-1.rds.amazonaws.com',\n",
       " 'port': 5432,\n",
       " 'username': 'bennisyiu',\n",
       " 'password': 'Yatpatyeh234',\n",
       " 'database': 'postgres',\n",
       " 'schema': 'public'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scopus_search_data_uploader(db_credentials, df, table_name='scopus_search_output'):\n",
    "    \"\"\"\n",
    "    Upload Scopus data to Postgres database.\n",
    "    Creates the table if it doesn't exist, then upserts data based on dc_identifier.\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    cursor = None\n",
    "    print('scopus_search_data_uploader() method')\n",
    "    \n",
    "    try:\n",
    "        # Data preprocessing\n",
    "        date_columns = ['prism_coverdate']\n",
    "        for col in date_columns:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "        df['publication_year'] = df['publication_year'].fillna(9999).astype(int)\n",
    "\n",
    "        # Connect to the Postgres database\n",
    "        conn = psycopg2.connect(\n",
    "            host=db_credentials['hostname'],\n",
    "            database=db_credentials['database'],\n",
    "            user=db_credentials['username'],\n",
    "            password=db_credentials['password'],\n",
    "            port=db_credentials['port'],\n",
    "            connect_timeout=30\n",
    "        )\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Set the schema\n",
    "        cursor.execute(sql.SQL(\"SET search_path TO {};\").format(\n",
    "            sql.Identifier(db_credentials['schema'])\n",
    "        ))\n",
    "\n",
    "        # Check if table exists, if not create it\n",
    "        cursor.execute(sql.SQL(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS {} (\n",
    "                fa BOOLEAN,\n",
    "                prism_url TEXT,\n",
    "                dc_identifier TEXT PRIMARY KEY,\n",
    "                prism_publicationname TEXT,\n",
    "                prism_coverdate DATE,\n",
    "                prism_doi TEXT,\n",
    "                citedby_count INTEGER,\n",
    "                subtype TEXT,\n",
    "                subtypedescription TEXT,\n",
    "                publication_year INTEGER\n",
    "            )\n",
    "        \"\"\").format(sql.Identifier(table_name)))\n",
    "\n",
    "        # Prepare the data for insertion\n",
    "        columns = df.columns.tolist()\n",
    "        \n",
    "        # Construct the INSERT ... ON CONFLICT DO UPDATE query\n",
    "        insert_query = sql.SQL(\"\"\"\n",
    "            INSERT INTO {} ({})\n",
    "            VALUES %s\n",
    "            ON CONFLICT (dc_identifier) DO UPDATE SET\n",
    "            {}\n",
    "        \"\"\").format(\n",
    "            sql.Identifier(table_name),\n",
    "            sql.SQL(', ').join(map(sql.Identifier, columns)),\n",
    "            sql.SQL(', ').join(\n",
    "                sql.SQL(\"{0} = EXCLUDED.{0}\").format(sql.Identifier(col))\n",
    "                for col in columns if col != 'dc_identifier'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Insert or update data in chunks\n",
    "        chunk_size = 50\n",
    "        for i in range(0, len(df), chunk_size):\n",
    "            chunk = df.iloc[i:i+chunk_size]\n",
    "            values = [tuple(row) for _, row in chunk.iterrows()]\n",
    "            execute_values(cursor, insert_query, values)\n",
    "            print(f\"Processed chunk of {len(chunk)} records\")\n",
    "\n",
    "        conn.commit()\n",
    "        print(f\"Successfully uploaded/updated data for {len(df)} records\")\n",
    "\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Database error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        raise e\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error: {e}\")\n",
    "        if conn:\n",
    "            conn.rollback()\n",
    "        raise e\n",
    "    finally:\n",
    "        if cursor:\n",
    "            cursor.close()\n",
    "        if conn:\n",
    "            conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2931ae25",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_df = pd.read_csv('polyu_research_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c3e1d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fa",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "prism_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dc_identifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prism_publicationname",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prism_coverdate",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prism_doi",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "citedby_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subtype",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subtypedescription",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "publication_year",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8a8531f5-98db-468f-bd34-abab28df86b3",
       "rows": [
        [
         "0",
         "True",
         "https://api.elsevier.com/content/abstract/scopus_id/85150042634",
         "SCOPUS_ID:85150042634",
         "ACS Nano",
         "2023-03-28 00:00:00",
         "10.1021/acsnano.2c12606",
         "664",
         "re",
         "Review",
         "2023"
        ],
        [
         "1",
         "True",
         "https://api.elsevier.com/content/abstract/scopus_id/85144234312",
         "SCOPUS_ID:85144234312",
         "Psychology and Marketing",
         "2023-04-01 00:00:00",
         "10.1002/mar.21767",
         "486",
         "ar",
         "Article",
         "2023"
        ],
        [
         "2",
         "True",
         "https://api.elsevier.com/content/abstract/scopus_id/85146445335",
         "SCOPUS_ID:85146445335",
         "Tourism Management",
         "2023-08-01 00:00:00",
         "10.1016/j.tourman.2023.104724",
         "468",
         "re",
         "Review",
         "2023"
        ],
        [
         "3",
         "True",
         "https://api.elsevier.com/content/abstract/scopus_id/85151316371",
         "SCOPUS_ID:85151316371",
         "Nature Communications",
         "2023-12-01 00:00:00",
         "10.1038/s41467-023-37526-5",
         "404",
         "ar",
         "Article",
         "2023"
        ],
        [
         "4",
         "True",
         "https://api.elsevier.com/content/abstract/scopus_id/85147606524",
         "SCOPUS_ID:85147606524",
         "Materials and Design",
         "2023-02-01 00:00:00",
         "10.1016/j.matdes.2023.111661",
         "349",
         "re",
         "Review",
         "2023"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fa</th>\n",
       "      <th>prism_url</th>\n",
       "      <th>dc_identifier</th>\n",
       "      <th>prism_publicationname</th>\n",
       "      <th>prism_coverdate</th>\n",
       "      <th>prism_doi</th>\n",
       "      <th>citedby_count</th>\n",
       "      <th>subtype</th>\n",
       "      <th>subtypedescription</th>\n",
       "      <th>publication_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scop...</td>\n",
       "      <td>SCOPUS_ID:85150042634</td>\n",
       "      <td>ACS Nano</td>\n",
       "      <td>2023-03-28 00:00:00</td>\n",
       "      <td>10.1021/acsnano.2c12606</td>\n",
       "      <td>664</td>\n",
       "      <td>re</td>\n",
       "      <td>Review</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scop...</td>\n",
       "      <td>SCOPUS_ID:85144234312</td>\n",
       "      <td>Psychology and Marketing</td>\n",
       "      <td>2023-04-01 00:00:00</td>\n",
       "      <td>10.1002/mar.21767</td>\n",
       "      <td>486</td>\n",
       "      <td>ar</td>\n",
       "      <td>Article</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scop...</td>\n",
       "      <td>SCOPUS_ID:85146445335</td>\n",
       "      <td>Tourism Management</td>\n",
       "      <td>2023-08-01 00:00:00</td>\n",
       "      <td>10.1016/j.tourman.2023.104724</td>\n",
       "      <td>468</td>\n",
       "      <td>re</td>\n",
       "      <td>Review</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scop...</td>\n",
       "      <td>SCOPUS_ID:85151316371</td>\n",
       "      <td>Nature Communications</td>\n",
       "      <td>2023-12-01 00:00:00</td>\n",
       "      <td>10.1038/s41467-023-37526-5</td>\n",
       "      <td>404</td>\n",
       "      <td>ar</td>\n",
       "      <td>Article</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scop...</td>\n",
       "      <td>SCOPUS_ID:85147606524</td>\n",
       "      <td>Materials and Design</td>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>10.1016/j.matdes.2023.111661</td>\n",
       "      <td>349</td>\n",
       "      <td>re</td>\n",
       "      <td>Review</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     fa                                          prism_url  \\\n",
       "0  True  https://api.elsevier.com/content/abstract/scop...   \n",
       "1  True  https://api.elsevier.com/content/abstract/scop...   \n",
       "2  True  https://api.elsevier.com/content/abstract/scop...   \n",
       "3  True  https://api.elsevier.com/content/abstract/scop...   \n",
       "4  True  https://api.elsevier.com/content/abstract/scop...   \n",
       "\n",
       "           dc_identifier     prism_publicationname      prism_coverdate  \\\n",
       "0  SCOPUS_ID:85150042634                  ACS Nano  2023-03-28 00:00:00   \n",
       "1  SCOPUS_ID:85144234312  Psychology and Marketing  2023-04-01 00:00:00   \n",
       "2  SCOPUS_ID:85146445335        Tourism Management  2023-08-01 00:00:00   \n",
       "3  SCOPUS_ID:85151316371     Nature Communications  2023-12-01 00:00:00   \n",
       "4  SCOPUS_ID:85147606524      Materials and Design  2023-02-01 00:00:00   \n",
       "\n",
       "                       prism_doi  citedby_count subtype subtypedescription  \\\n",
       "0        10.1021/acsnano.2c12606            664      re             Review   \n",
       "1              10.1002/mar.21767            486      ar            Article   \n",
       "2  10.1016/j.tourman.2023.104724            468      re             Review   \n",
       "3     10.1038/s41467-023-37526-5            404      ar            Article   \n",
       "4   10.1016/j.matdes.2023.111661            349      re             Review   \n",
       "\n",
       "   publication_year  \n",
       "0              2023  \n",
       "1              2023  \n",
       "2              2023  \n",
       "3              2023  \n",
       "4              2023  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b1906fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "fa",
         "rawType": "bool",
         "type": "boolean"
        },
        {
         "name": "prism_url",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "dc_identifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prism_publicationname",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prism_coverdate",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "prism_doi",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "citedby_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subtype",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subtypedescription",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "publication_year",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "00e93cb1-4e80-4363-9a0c-6a0e0a64ff2c",
       "rows": [
        [
         "27652",
         "True",
         "https://api.elsevier.com/content/abstract/scopus_id/85160096295",
         "SCOPUS_ID:85160096295",
         "Acta Geotechnica",
         "2024-01-01 00:00:00",
         "10.1007/s11440-023-01928-y",
         "2",
         "ar",
         "Article",
         "2024"
        ],
        [
         "27653",
         "True",
         "https://api.elsevier.com/content/abstract/scopus_id/85159675707",
         "SCOPUS_ID:85159675707",
         "IEEE Wireless Communications",
         "2024-06-01 00:00:00",
         "10.1109/MWC.019.2200606",
         "2",
         "ar",
         "Article",
         "2024"
        ],
        [
         "27654",
         "True",
         "https://api.elsevier.com/content/abstract/scopus_id/85159130476",
         "SCOPUS_ID:85159130476",
         "Environment, Development and Sustainability",
         "2024-07-01 00:00:00",
         "10.1007/s10668-023-03346-2",
         "2",
         "ar",
         "Article",
         "2024"
        ],
        [
         "27655",
         "True",
         "https://api.elsevier.com/content/abstract/scopus_id/85159066873",
         "SCOPUS_ID:85159066873",
         "International Social Work",
         "2024-03-01 00:00:00",
         "10.1177/00208728231165638",
         "2",
         "ar",
         "Article",
         "2024"
        ],
        [
         "27656",
         "True",
         "https://api.elsevier.com/content/abstract/scopus_id/85159041714",
         "SCOPUS_ID:85159041714",
         "Fire Technology",
         "2024-03-01 00:00:00",
         "10.1007/s10694-023-01416-5",
         "2",
         "ar",
         "Article",
         "2024"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fa</th>\n",
       "      <th>prism_url</th>\n",
       "      <th>dc_identifier</th>\n",
       "      <th>prism_publicationname</th>\n",
       "      <th>prism_coverdate</th>\n",
       "      <th>prism_doi</th>\n",
       "      <th>citedby_count</th>\n",
       "      <th>subtype</th>\n",
       "      <th>subtypedescription</th>\n",
       "      <th>publication_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27652</th>\n",
       "      <td>True</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scop...</td>\n",
       "      <td>SCOPUS_ID:85160096295</td>\n",
       "      <td>Acta Geotechnica</td>\n",
       "      <td>2024-01-01 00:00:00</td>\n",
       "      <td>10.1007/s11440-023-01928-y</td>\n",
       "      <td>2</td>\n",
       "      <td>ar</td>\n",
       "      <td>Article</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27653</th>\n",
       "      <td>True</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scop...</td>\n",
       "      <td>SCOPUS_ID:85159675707</td>\n",
       "      <td>IEEE Wireless Communications</td>\n",
       "      <td>2024-06-01 00:00:00</td>\n",
       "      <td>10.1109/MWC.019.2200606</td>\n",
       "      <td>2</td>\n",
       "      <td>ar</td>\n",
       "      <td>Article</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27654</th>\n",
       "      <td>True</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scop...</td>\n",
       "      <td>SCOPUS_ID:85159130476</td>\n",
       "      <td>Environment, Development and Sustainability</td>\n",
       "      <td>2024-07-01 00:00:00</td>\n",
       "      <td>10.1007/s10668-023-03346-2</td>\n",
       "      <td>2</td>\n",
       "      <td>ar</td>\n",
       "      <td>Article</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27655</th>\n",
       "      <td>True</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scop...</td>\n",
       "      <td>SCOPUS_ID:85159066873</td>\n",
       "      <td>International Social Work</td>\n",
       "      <td>2024-03-01 00:00:00</td>\n",
       "      <td>10.1177/00208728231165638</td>\n",
       "      <td>2</td>\n",
       "      <td>ar</td>\n",
       "      <td>Article</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27656</th>\n",
       "      <td>True</td>\n",
       "      <td>https://api.elsevier.com/content/abstract/scop...</td>\n",
       "      <td>SCOPUS_ID:85159041714</td>\n",
       "      <td>Fire Technology</td>\n",
       "      <td>2024-03-01 00:00:00</td>\n",
       "      <td>10.1007/s10694-023-01416-5</td>\n",
       "      <td>2</td>\n",
       "      <td>ar</td>\n",
       "      <td>Article</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         fa                                          prism_url  \\\n",
       "27652  True  https://api.elsevier.com/content/abstract/scop...   \n",
       "27653  True  https://api.elsevier.com/content/abstract/scop...   \n",
       "27654  True  https://api.elsevier.com/content/abstract/scop...   \n",
       "27655  True  https://api.elsevier.com/content/abstract/scop...   \n",
       "27656  True  https://api.elsevier.com/content/abstract/scop...   \n",
       "\n",
       "               dc_identifier                        prism_publicationname  \\\n",
       "27652  SCOPUS_ID:85160096295                             Acta Geotechnica   \n",
       "27653  SCOPUS_ID:85159675707                 IEEE Wireless Communications   \n",
       "27654  SCOPUS_ID:85159130476  Environment, Development and Sustainability   \n",
       "27655  SCOPUS_ID:85159066873                    International Social Work   \n",
       "27656  SCOPUS_ID:85159041714                              Fire Technology   \n",
       "\n",
       "           prism_coverdate                   prism_doi  citedby_count subtype  \\\n",
       "27652  2024-01-01 00:00:00  10.1007/s11440-023-01928-y              2      ar   \n",
       "27653  2024-06-01 00:00:00     10.1109/MWC.019.2200606              2      ar   \n",
       "27654  2024-07-01 00:00:00  10.1007/s10668-023-03346-2              2      ar   \n",
       "27655  2024-03-01 00:00:00   10.1177/00208728231165638              2      ar   \n",
       "27656  2024-03-01 00:00:00  10.1007/s10694-023-01416-5              2      ar   \n",
       "\n",
       "      subtypedescription  publication_year  \n",
       "27652            Article              2024  \n",
       "27653            Article              2024  \n",
       "27654            Article              2024  \n",
       "27655            Article              2024  \n",
       "27656            Article              2024  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e3a0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test DB connection\n",
    "# import psycopg2\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "\n",
    "# # Load environment variables\n",
    "# load_dotenv()\n",
    "\n",
    "# # Retrieve credentials\n",
    "# db_credentials = {\n",
    "#     'hostname': os.getenv('DB_HOST'),\n",
    "#     'port': int(os.getenv('DB_PORT', 5432)),\n",
    "#     'username': os.getenv('DB_USER'),\n",
    "#     'password': os.getenv('DB_PASSWORD'),\n",
    "#     'database': os.getenv('DB_NAME')\n",
    "# }\n",
    "\n",
    "# try:\n",
    "#     # Print credentials for debugging\n",
    "#     print(\"Hostname:\", db_credentials['hostname'])\n",
    "#     print(\"Port:\", db_credentials['port'])\n",
    "#     print(\"Username:\", db_credentials['username'])\n",
    "#     print(\"Password:\", \"*****\")\n",
    "#     print(\"Database:\", db_credentials['database'])\n",
    "\n",
    "#     # Attempt to connect to the database\n",
    "#     conn = psycopg2.connect(\n",
    "#         host=db_credentials['hostname'],\n",
    "#         port=db_credentials['port'],\n",
    "#         user=db_credentials['username'],\n",
    "#         password=db_credentials['password'],\n",
    "#         database=db_credentials['database']\n",
    "#     )\n",
    "#     print(\"Connection successful!\")\n",
    "#     conn.close()\n",
    "# except Exception as e:\n",
    "#     print(f\"Error connecting to the database: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faebbc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scopus_search_data_uploader() method\n",
      "Database error: connection to server at \"portfolio-projects.ctoiwe860cq9.ap-southeast-1.rds.amazonaws.com\" (13.214.114.30), port 5432 failed: timeout expired\n",
      "\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "connection to server at \"portfolio-projects.ctoiwe860cq9.ap-southeast-1.rds.amazonaws.com\" (13.214.114.30), port 5432 failed: timeout expired\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOperationalError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mscopus_search_data_uploader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb_credentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mscopus_search_output\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36mscopus_search_data_uploader\u001b[39m\u001b[34m(db_credentials, df, table_name)\u001b[39m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m conn:\n\u001b[32m     83\u001b[39m         conn.rollback()\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     86\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mscopus_search_data_uploader\u001b[39m\u001b[34m(db_credentials, df, table_name)\u001b[39m\n\u001b[32m     17\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mpublication_year\u001b[39m\u001b[33m'\u001b[39m] = df[\u001b[33m'\u001b[39m\u001b[33mpublication_year\u001b[39m\u001b[33m'\u001b[39m].fillna(\u001b[32m9999\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Connect to the Postgres database\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m conn = \u001b[43mpsycopg2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb_credentials\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhostname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb_credentials\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdatabase\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb_credentials\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43musername\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb_credentials\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpassword\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mport\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdb_credentials\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mport\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconnect_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m cursor = conn.cursor()\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Set the schema\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/ipao-portfolio-projects/myenv/lib/python3.12/site-packages/psycopg2/__init__.py:122\u001b[39m, in \u001b[36mconnect\u001b[39m\u001b[34m(dsn, connection_factory, cursor_factory, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     kwasync[\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m] = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33masync_\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    121\u001b[39m dsn = _ext.make_dsn(dsn, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m conn = \u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnection_factory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwasync\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cursor_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    124\u001b[39m     conn.cursor_factory = cursor_factory\n",
      "\u001b[31mOperationalError\u001b[39m: connection to server at \"portfolio-projects.ctoiwe860cq9.ap-southeast-1.rds.amazonaws.com\" (13.214.114.30), port 5432 failed: timeout expired\n"
     ]
    }
   ],
   "source": [
    "scopus_search_data_uploader(db_credentials, latest_df, table_name='scopus_search_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d935c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cbebc4b",
   "metadata": {},
   "source": [
    "### Abstract Retrieval API Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb26e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd1dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
